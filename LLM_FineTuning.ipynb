{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MkzUDOIg_x4",
        "outputId": "6b6ca933-f5fa-41ee-8d73-82da92efb038"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets\n",
        "!pip install -U mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7FYq1tul0nj",
        "outputId": "9d1e15f6-b8ef-476c-e8e3-8527d3ab869c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to all known laws of aviation, there is no way a bee should be able to fly.\n",
            "This is a very easy-to-use system that provides a user-friendly interface to a remote system. However, by keeping their own rules in mind, it does not allow a voice to make it uncomplicated or unbiased or excite infringement, or are trying to find a suitable tool for anyone who wants to look at all of their friends for a long time.\n",
            "It's very important to have great experiences in common areas of knowledge, such as for the purpose of training or teaching it or learning to have a career pathway\n",
            "Another way to gain access to information that may be valuable to the people of any other way in which the \"women are in the real world,\" which means they may have been better understand.\n",
            "In your experience, they cannot say what you are doing with others.\n",
            "In 2013, the people who do not know what it has to be.\n",
            "Things on the Internet. It is a very common thing for bothers, the good old ones are not in the beginning\n",
            "of the world, but the most significant\n",
            "the most profitable thing about it. I think that's how it would be easier for them to get away from your place.\n",
            "Those who do this when you've become more aware of the\n",
            "much lessons are the type of person who is. So many people can understand.\n",
            "Of course, a company\n",
            "you are on a single person or a person or a person\n",
            "to share what they offer. You don't always ask me?\n",
            "I can't tell you that, because I think\n",
            "is a person and a person has a person\n",
            "give personality. You can go to the person who works as an adult with\n",
            "the person who is passionate about the person.\n",
            "I'll be there to ask for a lot of persons who like me.\n",
            "I hate these persons. The person at an\n",
            "comparks for all their life in that they are not\n",
            "money in the same way in\n",
            "and a person in my life, but that is why I think about being a person\n",
            "and how things are good in the person\n",
            "I know I just can get something with them.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "MODEL_NAME = \"arnir0/Tiny-LLM\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def generate_text(prompt, model, tokenizer, max_length=512, temperature=1, top_k=50, top_p=0.95):\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_length=max_length,\n",
        "        temperature=temperature,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "def main():\n",
        "    # Define your prompt\n",
        "    prompt = \"According to all known laws of aviation, there is no way a bee should be able to fly.\"\n",
        "\n",
        "    generated_text = generate_text(prompt, model, tokenizer)\n",
        "\n",
        "    print(generated_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_-O7u9xgRM5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_dataset, concatenate_datasets\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-8_J75fW5_o"
      },
      "outputs": [],
      "source": [
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyjGaEVohUth",
        "outputId": "2ab5e817-5e12-43d1-ebf8-23ecf799aaf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['text', 'label'],\n",
              "     num_rows: 3534\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['text', 'label'],\n",
              "     num_rows: 27481\n",
              " }))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['test'], dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGtxtnHmh6oG"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train']\n",
        "eval_dataset = dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Y33v7XLhgvxR",
        "outputId": "69d5112c-ce7c-4e3f-de9e-515cb1b838f2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "feca53c7eedd47c3a75d103121496f2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3534 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwu-gOQSkY4s",
        "outputId": "c1474aad-1495-41f7-80fa-ad473a1778cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 27481\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1BsgtT6jo0m",
        "outputId": "96277373-8cf3-4482-cd2e-f8d265399a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': ' I`d have responded, if I were going', 'label': 1, 'input_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 29871, 306, 29952, 29881, 505, 10049, 287, 29892, 565, 306, 892, 2675], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_train_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKvZ8mElqn3k",
        "outputId": "f0ba00f0-1983-464c-d30f-44114ad164f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concatenated_dataset = concatenate_datasets([dataset['train'], dataset['test']])\n",
        "concatenated_dataset.unique('label')\n",
        "num_of_labels = len(concatenated_dataset.unique('label'))\n",
        "num_of_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmCE8MkYoT0k",
        "outputId": "c488a23b-262b-40c3-8ec4-a8cd0d9ffe79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at arnir0/Tiny-LLM and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_of_labels, pad_token_id=tokenizer.pad_token_id) # Adjust num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wSDZdMSoUtl"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG8rU0gA-PDU"
      },
      "source": [
        "# Need to try out MLFlow instead of WandB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmC6hGflanUm",
        "outputId": "2be148e9-31a3-4422-c9f9-b7049056f122"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/05/13 16:13:45 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2025/05/13 16:13:47 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/05/13 16:13:47 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
            "2025/05/13 16:13:47 WARNING mlflow.utils.autologging_utils: MLflow transformers autologging is known to be compatible with 4.35.2 <= transformers <= 4.51.2, but the installed version is 4.51.3. If you encounter errors during autologging, try upgrading / downgrading transformers to a compatible version, or try upgrading MLflow.\n",
            "2025/05/13 16:13:47 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n",
            "2025/05/13 16:13:47 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/05/13 16:13:47 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "mlflow.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "Ic5ZkewYbROS",
        "outputId": "367cdc89-8528-494c-f3b4-8d9621984360"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-5f109b7a53bf>:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='859' max='859' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [859/859 06:48, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.232200</td>\n",
              "      <td>0.937868</td>\n",
              "      <td>0.543011</td>\n",
              "      <td>0.512384</td>\n",
              "      <td>0.572892</td>\n",
              "      <td>0.543011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with mlflow.start_run():\n",
        "    # your training code goes here\n",
        "    # Initialize W&B\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=4e-3,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=32,\n",
        "        num_train_epochs=1,\n",
        "        weight_decay=0.01,\n",
        "        report_to=\"mlflow\",  # Enable mlflow integration\n",
        "        run_name=\"my-awesome-run\" # Custom run name\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train_dataset,\n",
        "        eval_dataset=tokenized_eval_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        processing_class=tokenizer\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oIm_F-rThxh7",
        "outputId": "c2369183-77bd-4cfd-ba39-fc9d6ded7ed8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Run: data=<RunData: metrics={'epoch': 1.0,\n",
              " 'eval_accuracy': 0.543010752688172,\n",
              " 'eval_f1': 0.5123836675709043,\n",
              " 'eval_loss': 0.9378683567047119,\n",
              " 'eval_precision': 0.5728921374638508,\n",
              " 'eval_recall': 0.543010752688172,\n",
              " 'eval_runtime': 21.1139,\n",
              " 'eval_samples_per_second': 167.378,\n",
              " 'eval_steps_per_second': 5.257,\n",
              " 'grad_norm': 4.675554275512695,\n",
              " 'learning_rate': 0.0016763678696158325,\n",
              " 'loss': 1.2322,\n",
              " 'total_flos': 236910062075904.0,\n",
              " 'train_loss': 1.1228706972701725,\n",
              " 'train_runtime': 409.2264,\n",
              " 'train_samples_per_second': 67.154,\n",
              " 'train_steps_per_second': 2.099}, params={'_attn_implementation_autoset': 'True',\n",
              " '_name_or_path': 'arnir0/Tiny-LLM',\n",
              " 'accelerator_config': \"{'split_batches': False, 'dispatch_batches': None, \"\n",
              "                       \"'even_batches': True, 'use_seedable_sampler': True, \"\n",
              "                       \"'non_blocking': False, 'gradient_accumulation_kwargs': \"\n",
              "                       'None}',\n",
              " 'adafactor': 'False',\n",
              " 'adam_beta1': '0.9',\n",
              " 'adam_beta2': '0.999',\n",
              " 'adam_epsilon': '1e-08',\n",
              " 'add_cross_attention': 'False',\n",
              " 'architectures': \"['LlamaForCausalLM']\",\n",
              " 'attention_bias': 'False',\n",
              " 'attention_dropout': '0.0',\n",
              " 'auto_find_batch_size': 'False',\n",
              " 'average_tokens_across_devices': 'False',\n",
              " 'bad_words_ids': 'None',\n",
              " 'batch_eval_metrics': 'False',\n",
              " 'begin_suppress_tokens': 'None',\n",
              " 'bf16': 'False',\n",
              " 'bf16_full_eval': 'False',\n",
              " 'bos_token_id': '1',\n",
              " 'chunk_size_feed_forward': '0',\n",
              " 'cross_attention_hidden_size': 'None',\n",
              " 'data_seed': 'None',\n",
              " 'dataloader_drop_last': 'False',\n",
              " 'dataloader_num_workers': '0',\n",
              " 'dataloader_persistent_workers': 'False',\n",
              " 'dataloader_pin_memory': 'True',\n",
              " 'dataloader_prefetch_factor': 'None',\n",
              " 'ddp_backend': 'None',\n",
              " 'ddp_broadcast_buffers': 'None',\n",
              " 'ddp_bucket_cap_mb': 'None',\n",
              " 'ddp_find_unused_parameters': 'None',\n",
              " 'ddp_timeout': '1800',\n",
              " 'debug': '[]',\n",
              " 'decoder_start_token_id': 'None',\n",
              " 'deepspeed': 'None',\n",
              " 'disable_tqdm': 'False',\n",
              " 'diversity_penalty': '0.0',\n",
              " 'do_eval': 'True',\n",
              " 'do_predict': 'False',\n",
              " 'do_sample': 'False',\n",
              " 'do_train': 'False',\n",
              " 'early_stopping': 'False',\n",
              " 'encoder_no_repeat_ngram_size': '0',\n",
              " 'eos_token_id': '2',\n",
              " 'eval_accumulation_steps': 'None',\n",
              " 'eval_delay': '0',\n",
              " 'eval_do_concat_batches': 'True',\n",
              " 'eval_on_start': 'False',\n",
              " 'eval_steps': 'None',\n",
              " 'eval_strategy': 'epoch',\n",
              " 'eval_use_gather_object': 'False',\n",
              " 'exponential_decay_length_penalty': 'None',\n",
              " 'finetuning_task': 'None',\n",
              " 'forced_bos_token_id': 'None',\n",
              " 'forced_eos_token_id': 'None',\n",
              " 'fp16': 'False',\n",
              " 'fp16_backend': 'auto',\n",
              " 'fp16_full_eval': 'False',\n",
              " 'fp16_opt_level': 'O1',\n",
              " 'fsdp': '[]',\n",
              " 'fsdp_config': \"{'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, \"\n",
              "                \"'xla_fsdp_grad_ckpt': False}\",\n",
              " 'fsdp_min_num_params': '0',\n",
              " 'fsdp_transformer_layer_cls_to_wrap': 'None',\n",
              " 'full_determinism': 'False',\n",
              " 'gradient_accumulation_steps': '1',\n",
              " 'gradient_checkpointing': 'False',\n",
              " 'gradient_checkpointing_kwargs': 'None',\n",
              " 'greater_is_better': 'None',\n",
              " 'group_by_length': 'False',\n",
              " 'half_precision_backend': 'auto',\n",
              " 'head_dim': '96',\n",
              " 'hidden_act': 'silu',\n",
              " 'hidden_size': '192',\n",
              " 'hub_always_push': 'False',\n",
              " 'hub_model_id': 'None',\n",
              " 'hub_private_repo': 'None',\n",
              " 'hub_strategy': 'every_save',\n",
              " 'hub_token': '<HUB_TOKEN>',\n",
              " 'id2label': \"{0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2'}\",\n",
              " 'ignore_data_skip': 'False',\n",
              " 'include_for_metrics': '[]',\n",
              " 'include_inputs_for_metrics': 'False',\n",
              " 'include_num_input_tokens_seen': 'False',\n",
              " 'include_tokens_per_second': 'False',\n",
              " 'initializer_range': '0.02',\n",
              " 'intermediate_size': '1024',\n",
              " 'is_decoder': 'False',\n",
              " 'is_encoder_decoder': 'False',\n",
              " 'jit_mode_eval': 'False',\n",
              " 'label2id': \"{'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}\",\n",
              " 'label_names': 'None',\n",
              " 'label_smoothing_factor': '0.0',\n",
              " 'learning_rate': '0.004',\n",
              " 'length_column_name': 'length',\n",
              " 'length_penalty': '1.0',\n",
              " 'load_best_model_at_end': 'False',\n",
              " 'local_rank': '0',\n",
              " 'log_level': 'passive',\n",
              " 'log_level_replica': 'warning',\n",
              " 'log_on_each_node': 'True',\n",
              " 'logging_dir': './results/runs/May13_16-25-01_dd3c42037a0a',\n",
              " 'logging_first_step': 'False',\n",
              " 'logging_nan_inf_filter': 'True',\n",
              " 'logging_steps': '500',\n",
              " 'logging_strategy': 'steps',\n",
              " 'lr_scheduler_kwargs': '{}',\n",
              " 'lr_scheduler_type': 'linear',\n",
              " 'max_grad_norm': '1.0',\n",
              " 'max_length': '20',\n",
              " 'max_position_embeddings': '1024',\n",
              " 'max_steps': '-1',\n",
              " 'metric_for_best_model': 'None',\n",
              " 'min_length': '0',\n",
              " 'mlp_bias': 'False',\n",
              " 'model_type': 'llama',\n",
              " 'mp_parameters': '',\n",
              " 'neftune_noise_alpha': 'None',\n",
              " 'no_cuda': 'False',\n",
              " 'no_repeat_ngram_size': '0',\n",
              " 'num_attention_heads': '2',\n",
              " 'num_beam_groups': '1',\n",
              " 'num_beams': '1',\n",
              " 'num_hidden_layers': '1',\n",
              " 'num_key_value_heads': '1',\n",
              " 'num_return_sequences': '1',\n",
              " 'num_train_epochs': '1',\n",
              " 'optim': 'adamw_torch',\n",
              " 'optim_args': 'None',\n",
              " 'optim_target_modules': 'None',\n",
              " 'output_attentions': 'False',\n",
              " 'output_dir': './results',\n",
              " 'output_hidden_states': 'False',\n",
              " 'output_scores': 'False',\n",
              " 'overwrite_output_dir': 'False',\n",
              " 'pad_token_id': '2',\n",
              " 'past_index': '-1',\n",
              " 'per_device_eval_batch_size': '32',\n",
              " 'per_device_train_batch_size': '32',\n",
              " 'per_gpu_eval_batch_size': 'None',\n",
              " 'per_gpu_train_batch_size': 'None',\n",
              " 'prediction_loss_only': 'False',\n",
              " 'prefix': 'None',\n",
              " 'pretraining_tp': '1',\n",
              " 'problem_type': 'None',\n",
              " 'pruned_heads': '{}',\n",
              " 'push_to_hub': 'False',\n",
              " 'push_to_hub_model_id': 'None',\n",
              " 'push_to_hub_organization': 'None',\n",
              " 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>',\n",
              " 'ray_scope': 'last',\n",
              " 'remove_invalid_values': 'False',\n",
              " 'remove_unused_columns': 'True',\n",
              " 'repetition_penalty': '1.0',\n",
              " 'report_to': \"['mlflow']\",\n",
              " 'restore_callback_states_from_checkpoint': 'False',\n",
              " 'resume_from_checkpoint': 'None',\n",
              " 'return_dict': 'True',\n",
              " 'return_dict_in_generate': 'False',\n",
              " 'rms_norm_eps': '1e-05',\n",
              " 'rope_scaling': 'None',\n",
              " 'rope_theta': '10000.0',\n",
              " 'run_name': 'my-awesome-run',\n",
              " 'save_on_each_node': 'False',\n",
              " 'save_only_model': 'False',\n",
              " 'save_safetensors': 'True',\n",
              " 'save_steps': '500',\n",
              " 'save_strategy': 'steps',\n",
              " 'save_total_limit': 'None',\n",
              " 'seed': '42',\n",
              " 'sep_token_id': 'None',\n",
              " 'skip_memory_metrics': 'True',\n",
              " 'suppress_tokens': 'None',\n",
              " 'task_specific_params': 'None',\n",
              " 'temperature': '1.0',\n",
              " 'tf32': 'None',\n",
              " 'tf_legacy_loss': 'False',\n",
              " 'tie_encoder_decoder': 'False',\n",
              " 'tie_word_embeddings': 'False',\n",
              " 'tokenizer_class': 'None',\n",
              " 'top_k': '50',\n",
              " 'top_p': '1.0',\n",
              " 'torch_compile': 'False',\n",
              " 'torch_compile_backend': 'None',\n",
              " 'torch_compile_mode': 'None',\n",
              " 'torch_dtype': 'float32',\n",
              " 'torch_empty_cache_steps': 'None',\n",
              " 'torchdynamo': 'None',\n",
              " 'torchscript': 'False',\n",
              " 'tp_size': '0',\n",
              " 'tpu_metrics_debug': 'False',\n",
              " 'tpu_num_cores': 'None',\n",
              " 'transformers_version': '4.51.3',\n",
              " 'typical_p': '1.0',\n",
              " 'use_bfloat16': 'False',\n",
              " 'use_cache': 'True',\n",
              " 'use_cpu': 'False',\n",
              " 'use_ipex': 'False',\n",
              " 'use_legacy_prediction_loop': 'False',\n",
              " 'use_liger_kernel': 'False',\n",
              " 'use_mps_device': 'False',\n",
              " 'vocab_size': '32000',\n",
              " 'warmup_ratio': '0.0',\n",
              " 'warmup_steps': '0',\n",
              " 'weight_decay': '0.01'}, tags={'mlflow.runName': 'capable-auk-759',\n",
              " 'mlflow.source.name': '/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py',\n",
              " 'mlflow.source.type': 'LOCAL',\n",
              " 'mlflow.user': 'root'}>, info=<RunInfo: artifact_uri='file:///content/mlruns/0/0d64268293dd495e91308c7124041f61/artifacts', end_time=1747153911588, experiment_id='0', lifecycle_stage='active', run_id='0d64268293dd495e91308c7124041f61', run_name='capable-auk-759', run_uuid='0d64268293dd495e91308c7124041f61', start_time=1747153501862, status='FINISHED', user_id='root'>, inputs=<RunInputs: dataset_inputs=[]>>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlflow.last_active_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARhQR1M_gpvq"
      },
      "outputs": [],
      "source": [
        "# In one cell, run this to start MLflow UI in the background:\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R5Tb8eXhbmj",
        "outputId": "b2cd0b18-d0ac-492a-a642-c4854ac38e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://8717-34-16-235-223.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok -q\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace \"YOUR_AUTHTOKEN\" with your actual authtoken\n",
        "ngrok.set_auth_token(\"2x37djQBYiKtStTpbABhLL8XwuM_3RaK7yMctKoBP36VRZzxa\")\n",
        "\n",
        "public_url = ngrok.connect(5000) # Default MLflow UI port\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKs0JhOPk1HM",
        "outputId": "92512323-9f71-413c-9f30-bb1aa71d5c7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://945d-34-16-235-223.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "# Kill existing processes\n",
        "!kill $(ps aux | grep '[n]grok' | awk '{print $2}') > /dev/null 2>&1\n",
        "!kill $(ps aux | grep '[m]lflow ui' | awk '{print $2}') > /dev/null 2>&1\n",
        "\n",
        "# Start MLflow UI, explicitly binding to 0.0.0.0\n",
        "get_ipython().system_raw(\"mlflow ui --host 0.0.0.0 --port 5000 &\")\n",
        "\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "from pyngrok import ngrok\n",
        "# ngrok.set_auth_token(\"YOUR_AUTHTOKEN\") # Assumed done\n",
        "public_url = ngrok.connect(addr=\"5000\", proto=\"http\")\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01hfOeogoNFQ"
      },
      "outputs": [],
      "source": [
        "!cp -r ./mlruns \"/content/drive/MyDrive/Colab Notebooks/LLM Fine-tuning Training/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G80mcEDoUwm"
      },
      "outputs": [],
      "source": [
        "# # Initialize W&B\n",
        "# wandb.init(project=\"sentiment-analysis\")\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./results\",\n",
        "#     eval_strategy=\"epoch\",\n",
        "#     learning_rate=4e-3,\n",
        "#     per_device_train_batch_size=32,\n",
        "#     per_device_eval_batch_size=32,\n",
        "#     num_train_epochs=1,\n",
        "#     weight_decay=0.01,\n",
        "#     report_to=\"wandb\",  # Enable WandB integration\n",
        "#     run_name=\"my-awesome-run\" # Custom run name\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=tokenized_train_dataset,\n",
        "#     eval_dataset=tokenized_eval_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "#     tokenizer=tokenizer\n",
        "# )\n",
        "\n",
        "# trainer.train()\n",
        "\n",
        "# wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5-IPWBhoVmJ",
        "outputId": "19af638e-f3da-4d86-e200-3b5e6a21eb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: 0\n"
          ]
        }
      ],
      "source": [
        "text = \"rtherhte rhte rher hre herh erth \"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predicted_class = torch.argmax(predictions).item()\n",
        "print(f\"Predicted Class: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_ujqG7PoVeY",
        "outputId": "cf164b84-10cc-46f8-a06b-5053fe301390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[ 180  746   75]\n",
            " [ 125 1136  169]\n",
            " [  22  478  603]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "model.to(\"cuda\")  # Ensure model is on GPU\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "for i in range(len(tokenized_eval_dataset)):\n",
        "    batch = tokenized_eval_dataset[i]\n",
        "    with torch.no_grad():\n",
        "        input_ids = torch.tensor(batch['input_ids']).unsqueeze(0).to(\"cuda\") # Add batch dimension\n",
        "        attention_mask = torch.tensor(batch['attention_mask']).unsqueeze(0).to(\"cuda\") # Add batch dimension\n",
        "        labels = torch.tensor(batch['label']).unsqueeze(0).to(\"cuda\") # Add batch dimension\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels) #Pass labels\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "        all_preds.extend(predictions)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvGEPn2VoUzU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3508a6c4f545415394ddef0a818c0d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566624ba6af648b5a17ca5a54792368c",
            "placeholder": "​",
            "style": "IPY_MODEL_5283db57227d459fa6cafcdfb784c9f1",
            "value": "Map: 100%"
          }
        },
        "3b3e72f4124d41a39212d2cae1c64737": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5283db57227d459fa6cafcdfb784c9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5362d90b31494d4aac51a40e5673213f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed7de3bbd29e4df486234dd7c3b4dc2d",
            "placeholder": "​",
            "style": "IPY_MODEL_f266c2d49e9e4ee5bf98cb3ac0c2e667",
            "value": " 3534/3534 [00:02&lt;00:00, 1309.28 examples/s]"
          }
        },
        "566624ba6af648b5a17ca5a54792368c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b89574726f4b81973658df2728e571": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a180ab41faed4b0b8988ef807c54a6d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacab92c5ffa4c8e9f2a9ad18da9d288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3e72f4124d41a39212d2cae1c64737",
            "max": 3534,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68b89574726f4b81973658df2728e571",
            "value": 3534
          }
        },
        "ed7de3bbd29e4df486234dd7c3b4dc2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f266c2d49e9e4ee5bf98cb3ac0c2e667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feca53c7eedd47c3a75d103121496f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3508a6c4f545415394ddef0a818c0d3a",
              "IPY_MODEL_bacab92c5ffa4c8e9f2a9ad18da9d288",
              "IPY_MODEL_5362d90b31494d4aac51a40e5673213f"
            ],
            "layout": "IPY_MODEL_a180ab41faed4b0b8988ef807c54a6d5"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
